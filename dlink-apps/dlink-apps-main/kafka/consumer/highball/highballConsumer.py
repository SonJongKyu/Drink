import os
import json
import logging
from kafka import KafkaConsumer
from pymongo import MongoClient

# âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
KAFKA_BROKER = os.getenv("KAFKA_BROKER", "localhost:9092")
MONGO_URI = os.getenv("MONGO_URI", "mongodb://admin:admin@localhost:27017/")
DATABASE_NAME = os.getenv("DATABASE_NAME", "dlink_db")
TOPIC_NAMES = os.getenv("TOPIC_NAME", "highballTopic").split(",")  # âœ… ì—¬ëŸ¬ ê°œì˜ í† í”½ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
COLLECTION_NAMES = os.getenv("COLLECTION_NAME", "highball").split(",")  # âœ… ì—¬ëŸ¬ ê°œì˜ ì»¬ë ‰ì…˜ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

# âœ… Kafka Consumer ì¢…ë£Œ ì¡°ê±´
POLL_TIMEOUT_SECONDS = int(os.getenv("POLL_TIMEOUT_SECONDS", "15"))  # âœ… í¬ë¡¤ë§ ì¢…ë£Œ í›„ ëŒ€ê¸° ì‹œê°„

# âœ… MongoDB ì—°ê²°
mongo_client = MongoClient(MONGO_URI)
db = mongo_client[DATABASE_NAME]

# âœ… Kafka Consumer ì„¤ì •
consumer = KafkaConsumer(
    *TOPIC_NAMES,
    bootstrap_servers=KAFKA_BROKER.split(","),
    auto_offset_reset="earliest",
    enable_auto_commit=True,
    group_id="highballConsumerGroup",
    value_deserializer=lambda v: json.loads(v.decode("utf-8")),
)

logging.basicConfig(level=logging.INFO)
logging.info(f"Kafka Consumer ì‹œì‘ - í† í”½: {TOPIC_NAMES}, DB: {DATABASE_NAME}, Collections: {COLLECTION_NAMES}")

# âœ… í† í”½ê³¼ ì»¬ë ‰ì…˜ ë§¤í•‘ (ê°œìˆ˜ê°€ ë‹¤ë¥¼ ê²½ìš° ê¸°ë³¸ì ìœ¼ë¡œ 1:1 ë§¤í•‘)
topic_collection_map = dict(zip(TOPIC_NAMES, COLLECTION_NAMES))

def consumeMessages():
    """Kafkaì—ì„œ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì™€ MongoDBì— ì €ì¥í•˜ê³  í¬ë¡¤ë§ì´ ëë‚˜ë©´ ì¢…ë£Œ"""
    while True:
        messages = consumer.poll(timeout_ms=POLL_TIMEOUT_SECONDS * 1000)  # âœ… ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°

        if not messages:  # âœ… ì¼ì • ì‹œê°„ ë™ì•ˆ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
            logging.info(f"ğŸ“Œ {POLL_TIMEOUT_SECONDS}ì´ˆ ë™ì•ˆ ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì—†ì–´ Consumer ì¢…ë£Œ.")
            break

        for topic_partition, records in messages.items():
            topic = topic_partition.topic  # âœ… í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í† í”½
            collection_name = topic_collection_map.get(topic)  # âœ… í•´ë‹¹ í† í”½ì— ëŒ€ì‘í•˜ëŠ” ì»¬ë ‰ì…˜

            if not collection_name:
                logging.warning(f"âš ï¸ {topic}ì— ëŒ€í•œ ë§¤í•‘ëœ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            collection = db[collection_name]  # âœ… ì»¬ë ‰ì…˜ ì„ íƒ

            for message in records:
                try:
                    data = message.value
                    if isinstance(data, dict) and "korName" in data:
                        logging.info(f"âœ… ì†Œë¹„ëœ ë°ì´í„°: {data['korName']} - {data.get('engName', 'N/A')} (í† í”½: {topic}, ì»¬ë ‰ì…˜: {collection_name})")

                        # âœ… MongoDBì— ë°ì´í„° ì €ì¥
                        collection.insert_one(data)
                        logging.info(f"âœ… MongoDB ì €ì¥ ì™„ë£Œ! {data['korName']} (ì»¬ë ‰ì…˜: {collection_name})")

                    else:
                        logging.warning(f"âš ï¸ ì˜¬ë°”ë¥´ì§€ ì•Šì€ ë°ì´í„° í˜•ì‹: {data}")

                except Exception as e:
                    logging.error(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    consumer.close()  # âœ… Kafka Consumer ì¢…ë£Œ
    logging.info("ğŸ›‘ Kafka Consumer ì •ìƒ ì¢…ë£Œ.")

if __name__ == "__main__":
    consumeMessages()

